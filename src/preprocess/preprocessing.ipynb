{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a528986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import drop_useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv('../../data/test_airbnb_berlin.xls')\n",
    "data_train=pd.read_csv('../../data/train_airbnb_berlin.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafa542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualisation\n",
    "\n",
    "# computing number of rows\n",
    "rows = len(data_train.axes[0])\n",
    "print('number row :',rows)\n",
    "# computing number of columns\n",
    "cols = len(data_train.axes[1])\n",
    "print('number columns :',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53536aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=drop_useless(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3dd137",
   "metadata": {},
   "source": [
    "__Analyse du taux de missing par feature__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb89ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des features avec un taux de \"missing\" moyen (~18%)\n",
    "listfeatures=[] \n",
    "\n",
    "def missing(df):\n",
    "    total = 0\n",
    "    for col in df.columns:\n",
    "        miss = df[col].isnull().sum()\n",
    "        pct = df[col].isna().mean() * 100\n",
    "        total += miss\n",
    "        if miss != 0:\n",
    "            print('{} => {} [{}%]'.format(col, df[col].isnull().sum(), round(pct, 2)))\n",
    "            if pct>15 and pct <25 :\n",
    "                listfeatures.append(col)\n",
    "        #else:\n",
    "        #    print('{} => {} '.format(col, 'no missing value'))\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"no missing values\")\n",
    "        \n",
    "missing(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d6ae0",
   "metadata": {},
   "source": [
    "__Gestion des features à taux de \"missing\" extrême__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb23f127",
   "metadata": {},
   "source": [
    "Lorsque l'on regarde les features où il manque moins de 30 données, on se rend compte que l'absence de ces données est MCAR. On se permet donc de supprimer les lignes où ces données sont manquantes. \n",
    "Il y a une exception sur la feature 'Is Superhost': si pour ces host il y a une note générale au dessus de 80, on les catégorises en Superhost, sinon, non. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68455134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des features à taux de missing trop élevé \n",
    "data_train=data_train.drop(['Square Feet','Host Response Time','Host Response Rate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listwise deletion pour les features à taux de missing faible (borne max des rows concernés : 60 /15k = 0.4%)\n",
    "for j in ['Price','Bathrooms','Bedrooms','Beds']:\n",
    "    for i in data_train[data_train[j].isna()== True].index:\n",
    "        data_train=data_train.drop(i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c217f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion des 'Is Superhost' : si le host est noté, et ce au dessus de 80, il est supposé superhost, sinon il ne l'est pas\n",
    "for i in data_train[data_train['Is Superhost'].isna()== True].index:\n",
    "    if data_train.loc[i,'Overall Rating']>=80:\n",
    "        data_train.loc[i,'Is Superhost']='t'\n",
    "    else:\n",
    "        data_train.loc[i,'Is Superhost']='f'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739cd7a",
   "metadata": {},
   "source": [
    "__Recherche de corrélations entre les features présentant un taux de missing value \"NaN\" autour de 18%__\n",
    "\n",
    "On va s'aider de la liste **listfeatures** définie plus tôt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tableau de correlation de \"missing\" entre deux features\n",
    "tablefeatures=np.ones((len(listfeatures),len(listfeatures)))\n",
    "\n",
    "#calcul des corrélations de missing entre deux features\n",
    "index1=0 \n",
    "for q in listfeatures:\n",
    "    nanrows=len(data_train[data_train[q].isna()== True].axes[0])\n",
    "    index2=0\n",
    "    for p in listfeatures :\n",
    "        if q!=p:\n",
    "            bothmiss=len(data_train[data_train[q].isna()== True][data_train[p].isna()== True].axes[0])\n",
    "        #print (\"P(\"+q+\" et \"+p+\" vaut NaN) =\" + str(bothmiss/nanrows))\n",
    "            tablefeatures[index1,index2]=bothmiss/nanrows\n",
    "        index2+=1\n",
    "    index1+=1   \n",
    "\n",
    "#affichage du tableau de corrélations\n",
    "print(\"Pourcentage minimal de corrélation entre deux features de la liste : \" + str(round(tablefeatures.min()*100,2)) + \"% \\n\")\n",
    "print(tablefeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5896d4a1",
   "metadata": {},
   "source": [
    "On peut donc raisonnablement affirmer que ces features sont de type MNAR : une listwise deletion n'est donc pas conseillée (et avec 18% d'instances concernées, ce n'est pas idéal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7c8c5",
   "metadata": {},
   "source": [
    "__Enregistrement__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5540d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import NA\n",
    "data_train.replace(\"*\", NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fichier csv où l'on sans les ratings \n",
    "data_train_clean=data_train.drop(['Overall Rating', 'Accuracy Rating', 'Cleanliness Rating',\n",
    "       'Checkin Rating', 'Communication Rating', 'Location Rating','Value Rating'], axis=1)\n",
    "data_train_clean.to_csv('../../data/data_train_clean.csv',index=False)\n",
    "\n",
    "#fichier csv où l'on garde les ratings \n",
    "\n",
    "for j in ['Overall Rating', 'Accuracy Rating', 'Cleanliness Rating','Checkin Rating', 'Communication Rating', 'Location Rating','Value Rating']:\n",
    "       for i in data_train_clean_ratings_included[data_train_clean_ratings_included[j].isna()== True].index:\n",
    "              data_train_clean_ratings_included=data_train_clean_ratings_included.drop(i, axis=0)\n",
    "\n",
    "data_train_clean_ratings_included.to_csv('../../data/data_train_clean_ratings_included.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f449c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d353b0c5e377b70cf8d68715abfc75cf273a5427d1952db2f540f22618aa254a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
